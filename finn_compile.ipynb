{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1918663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import brevitas.nn as qnn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "164d1d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrevitasIEEE(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super().__init__()\n",
    "        myWeight_bit_width = 2\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Identity(),\n",
    "\n",
    "            qnn.QuantConv2d(1, 16, kernel_size=(1, 5),\n",
    "                            weight_bit_width=myWeight_bit_width),\n",
    "            qnn.QuantReLU(inplace=True, weight_bit_width=myWeight_bit_width),\n",
    "            qnn.QuantConv2d(16, 32, kernel_size=(1, 5),\n",
    "                            weight_bit_width=myWeight_bit_width),\n",
    "            qnn.QuantReLU(inplace=True, weight_bit_width=myWeight_bit_width),\n",
    "            nn.MaxPool2d(kernel_size=(1, 4), stride=(1, 4)),\n",
    "\n",
    "            qnn.QuantConv2d(32, 16, kernel_size=(1, 3),\n",
    "                            weight_bit_width=myWeight_bit_width),\n",
    "            qnn.QuantReLU(inplace=True, weight_bit_width=myWeight_bit_width),\n",
    "            qnn.QuantConv2d(16, 16, kernel_size=(1, 3),\n",
    "                            weight_bit_width=myWeight_bit_width),\n",
    "            qnn.QuantReLU(inplace=True, weight_bit_width=myWeight_bit_width),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            qnn.QuantLinear(16 * 13, num_classes, bias=True,\n",
    "                            weight_bit_width=myWeight_bit_width),\n",
    "            # qnn.QuantLinear(10, num_classes, bias=False,\n",
    "            #                 weight_bit_width=myWeight_bit_width),\n",
    "            # qnn.QuantLinear(40, num_classes, bias=False,\n",
    "            #                 weight_bit_width=myWeight_bit_width, return_quant_tensor=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        # x = x.view(x.size(0), 128 * 28)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d7fd1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BrevitasIEEE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1abb9ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# trained_state_dict = torch.load(\"brevitas.pth\")[\"models_state_dict\"][0]\n",
    "trained_state_dict = torch.load(\"brevitas09.pth\")[\"state_dict\"]\n",
    "\n",
    "# print(trained_state_dict)\n",
    "\n",
    "model.load_state_dict(trained_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ca74eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1, 1, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "modified_model = deepcopy(model)\n",
    "\n",
    "# print(modified_model.features[0].weight.data.detach().numpy())\n",
    "W_orig = modified_model.features[1].weight.data.detach().numpy()\n",
    "W_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f792fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.nn import QuantIdentity\n",
    "\n",
    "\n",
    "class BrevitasIEEEForExport(nn.Module):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(BrevitasIEEEForExport, self).__init__()\n",
    "#         self.qnt_input = QuantIdentity(quant_type=QuantType.FP, bit_width=32)\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self.qnt_output = QuantIdentity(quant_type=QuantType.INT, bit_width=8)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # assume x contains bipolar {-1,1} elems\n",
    "        # shift from {-1,1} -> {0,1} since that is the\n",
    "        # input range for the trained network\n",
    "#         x = (x + torch.tensor([1.0])) / 2.0  \n",
    "        out_original = self.pretrained(x)\n",
    "        out_final = self.qnt_output(out_original)   # output as {-1,1}     \n",
    "        return out_final\n",
    "\n",
    "model_for_export = BrevitasIEEEForExport(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50336141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to brevitas09-IEEE-ready.onnx\n"
     ]
    }
   ],
   "source": [
    "# import brevitas.onnx as bo\n",
    "# from brevitas.quant_tensor import QuantTensor\n",
    "\n",
    "# ready_model_filename = \"brevitas07-IEEE-ready.onnx\"\n",
    "# input_shape = (1,1,1,128)\n",
    "# # create a QuantTensor instance to mark input as bipolar during export\n",
    "# input_a = np.random.randint(0, 1, size=input_shape).astype(np.float32)\n",
    "# # input_a = 2 * input_a - 1\n",
    "# scale = 1.0\n",
    "# input_t = torch.from_numpy(input_a * scale)\n",
    "# input_qt = QuantTensor(\n",
    "#     input_t, scale=torch.tensor(scale), bit_width=torch.tensor(32.0), signed=True\n",
    "# )\n",
    "\n",
    "# bo.export_finn_onnx(\n",
    "#     model, export_path=ready_model_filename, input_t=input_qt\n",
    "# )\n",
    "\n",
    "# print(\"Model saved to %s\" % ready_model_filename)\n",
    "import brevitas.onnx as bo\n",
    "from brevitas.quant_tensor import QuantTensor\n",
    "\n",
    "ready_model_filename = \"brevitas09-IEEE-ready.onnx\"\n",
    "input_shape = (1,1,1,128)\n",
    "# create a QuantTensor instance to mark input as bipolar during export\n",
    "input_a = np.random.randint(0, 1, size=input_shape).astype(np.float32)\n",
    "# input_a = 2 * input_a - 1\n",
    "scale = 1.0\n",
    "\n",
    "input_t = torch.from_numpy(input_a * scale)\n",
    "input_qt = QuantTensor(\n",
    "    input_t, scale=torch.tensor(scale), bit_width=torch.tensor(8.0), signed=True\n",
    ")\n",
    "\n",
    "# print(input_qt)\n",
    "bo.export_finn_onnx(\n",
    "    model_for_export, export_path=ready_model_filename, input_t=input_qt\n",
    ")\n",
    "\n",
    "print(\"Model saved to %s\" % ready_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd11420e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'brevitas09-IEEE-ready.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f2303413100>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(ready_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef386dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0193, -0.0887, -0.3648, -0.3569, -0.1951, -0.1704, -0.3849, -0.2674]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "pred = model(input_t)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da1f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.core.modelwrapper import ModelWrapper\n",
    "\n",
    "ready_model_filename = \"brevitas09-IEEE-ready.onnx\"\n",
    "model_for_sim = ModelWrapper(ready_model_filename)\n",
    "# dir(model_for_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a31f594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor name: 0\n",
      "Output tensor name: 78\n",
      "Input tensor shape: [1, 1, 1, 128]\n",
      "Output tensor shape: [1, 8]\n",
      "Input tensor datatype: INT8\n",
      "Output tensor datatype: FLOAT32\n",
      "List of node operator types in the graph: \n",
      "['Mul', 'Conv', 'Mul', 'Add', 'MultiThreshold', 'Mul', 'Conv', 'Mul', 'Add', 'MultiThreshold', 'Mul', 'MaxPool', 'Conv', 'Mul', 'Add', 'MultiThreshold', 'Mul', 'Conv', 'Mul', 'Add', 'MultiThreshold', 'Mul', 'MaxPool', 'Shape', 'Gather', 'Unsqueeze', 'Concat', 'Reshape', 'MatMul', 'Mul', 'Add', 'MultiThreshold', 'Add', 'Mul']\n"
     ]
    }
   ],
   "source": [
    "from finn.core.datatype import DataType\n",
    "\n",
    "finnonnx_in_tensor_name = model_for_sim.graph.input[0].name\n",
    "finnonnx_out_tensor_name = model_for_sim.graph.output[0].name\n",
    "print(\"Input tensor name: %s\" % finnonnx_in_tensor_name)\n",
    "print(\"Output tensor name: %s\" % finnonnx_out_tensor_name)\n",
    "finnonnx_model_in_shape = model_for_sim.get_tensor_shape(finnonnx_in_tensor_name)\n",
    "finnonnx_model_out_shape = model_for_sim.get_tensor_shape(finnonnx_out_tensor_name)\n",
    "print(\"Input tensor shape: %s\" % str(finnonnx_model_in_shape))\n",
    "print(\"Output tensor shape: %s\" % str(finnonnx_model_out_shape))\n",
    "finnonnx_model_in_dt = model_for_sim.get_tensor_datatype(finnonnx_in_tensor_name)\n",
    "finnonnx_model_out_dt = model_for_sim.get_tensor_datatype(finnonnx_out_tensor_name)\n",
    "print(\"Input tensor datatype: %s\" % str(finnonnx_model_in_dt.name))\n",
    "print(\"Output tensor datatype: %s\" % str(finnonnx_model_out_dt.name))\n",
    "print(\"List of node operator types in the graph: \")\n",
    "print([x.op_type for x in model_for_sim.graph.node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d602ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "from finn.transformation.change_3d_tensors_to_4d import Change3DTo4DTensors\n",
    "\n",
    "model_for_sim = model_for_sim.transform(InferShapes())\n",
    "model_for_sim = model_for_sim.transform(FoldConstants())\n",
    "model_for_sim = model_for_sim.transform(GiveUniqueNodeNames())\n",
    "model_for_sim = model_for_sim.transform(GiveReadableTensorNames())\n",
    "model_for_sim = model_for_sim.transform(InferDataTypes())\n",
    "model_for_sim = model_for_sim.transform(RemoveStaticGraphInputs())\n",
    "# model_for_sim = model_for_sim.transform(Change3DTo4DTensors())\n",
    "model_for_sim = model_for_sim.transform(Change3DTo4DTensors())\n",
    "\n",
    "verif_model_filename = \"brevitas09-IEEE-verification.onnx\"\n",
    "model_for_sim.save(verif_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c553ad23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'brevitas09-IEEE-verification.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f2302367400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(verif_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cdcb510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n"
     ]
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_file = \"brevitas09-IEEE-ready.onnx\"\n",
    "\n",
    "estimates_output_dir = \"output_estimates_only\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 10000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    board               = \"Pynq-Z2\",\n",
    "    steps               = build_cfg.estimate_only_dataflow_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd4041e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from brevitas09-IEEE-ready.onnx\n",
      "Intermediate outputs will be generated in /home/ian/build\n",
      "Final outputs will be generated in output_estimates_only\n",
      "Build log is at output_estimates_only/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/8]\n",
      "Running step: step_tidy_up [2/8]\n",
      "Running step: step_streamline [3/8]\n",
      "Running step: step_convert_to_hls [4/8]\n",
      "Running step: step_create_dataflow_partition [5/8]\n",
      "Running step: step_target_fps_parallelization [6/8]\n",
      "Running step: step_apply_folding_config [7/8]\n",
      "Running step: step_generate_estimate_reports [8/8]\n",
      "Completed successfully\n",
      "CPU times: user 3.19 s, sys: 16.1 ms, total: 3.21 s\n",
      "Wall time: 3.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b3904f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"critical_path_cycles\": 36882,\r\n",
      "  \"max_cycles\": 9984,\r\n",
      "  \"max_cycles_node_name\": \"StreamingFCLayer_Batch_3\",\r\n",
      "  \"estimated_throughput_fps\": 10016.02564102564,\r\n",
      "  \"estimated_latency_ns\": 368820.0\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat {estimates_output_dir}/report/estimate_network_performance.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "712a72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def read_json_dict(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        ret = json.load(f)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68173ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ConvolutionInputGenerator1D_0': 129,\n",
       " 'StreamingFCLayer_Batch_0': 9920,\n",
       " 'ConvolutionInputGenerator1D_1': 125,\n",
       " 'StreamingFCLayer_Batch_1': 7680,\n",
       " 'StreamingMaxPool_Batch_0': 124,\n",
       " 'ConvolutionInputGenerator1D_2': 31,\n",
       " 'StreamingFCLayer_Batch_2': 7168,\n",
       " 'ConvolutionInputGenerator1D_3': 29,\n",
       " 'StreamingFCLayer_Batch_3': 9984,\n",
       " 'StreamingMaxPool_Batch_1': 28,\n",
       " 'StreamingFCLayer_Batch_4': 1664}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_json_dict(estimates_output_dir + \"/report/estimate_layer_cycles.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eab6a479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ConvolutionInputGenerator1D_0': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 396,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'StreamingFCLayer_Batch_0': {'BRAM_18K': 1,\n",
       "  'BRAM_efficiency': 0.008680555555555556,\n",
       "  'LUT': 7651,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'ConvolutionInputGenerator1D_1': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 1836,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'StreamingFCLayer_Batch_1': {'BRAM_18K': 3,\n",
       "  'BRAM_efficiency': 0.09259259259259259,\n",
       "  'LUT': 12044,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'StreamingMaxPool_Batch_0': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 0,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'ConvolutionInputGenerator1D_2': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 1324,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'StreamingFCLayer_Batch_2': {'BRAM_18K': 1,\n",
       "  'BRAM_efficiency': 0.16666666666666666,\n",
       "  'LUT': 10174,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'ConvolutionInputGenerator1D_3': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 812,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'StreamingFCLayer_Batch_3': {'BRAM_18K': 1,\n",
       "  'BRAM_efficiency': 0.08333333333333333,\n",
       "  'LUT': 9392,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'StreamingMaxPool_Batch_1': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 0,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'StreamingFCLayer_Batch_4': {'BRAM_18K': 1,\n",
       "  'BRAM_efficiency': 0.18055555555555555,\n",
       "  'LUT': 10461,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'total': {'BRAM_18K': 7.0, 'LUT': 54090.0, 'URAM': 0.0, 'DSP': 0.0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_json_dict(estimates_output_dir + \"/report/estimate_layer_resources.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5b842ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n"
     ]
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_file = \"brevitas09-IEEE-ready.onnx\"\n",
    "\n",
    "final_output_dir = \"output_final\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(final_output_dir):\n",
    "    shutil.rmtree(final_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "\n",
    "cfg = build.DataflowBuildConfig(\n",
    "    output_dir          = final_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 10000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    board               = \"Pynq-Z2\",\n",
    "    shell_flow_type     = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8300564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from brevitas09-IEEE-ready.onnx\n",
      "Intermediate outputs will be generated in /home/ian/build\n",
      "Final outputs will be generated in output_final\n",
      "Build log is at output_final/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/17]\n",
      "Running step: step_tidy_up [2/17]\n",
      "Running step: step_streamline [3/17]\n",
      "Running step: step_convert_to_hls [4/17]\n",
      "Running step: step_create_dataflow_partition [5/17]\n",
      "Running step: step_target_fps_parallelization [6/17]\n",
      "Running step: step_apply_folding_config [7/17]\n",
      "Running step: step_generate_estimate_reports [8/17]\n",
      "Running step: step_hls_codegen [9/17]\n",
      "Running step: step_hls_ipgen [10/17]\n",
      "Running step: step_set_fifo_depths [11/17]\n",
      "Running step: step_create_stitched_ip [12/17]\n",
      "Running step: step_measure_rtlsim_performance [13/17]\n",
      "Running step: step_out_of_context_synthesis [14/17]\n",
      "Running step: step_synthesize_bitfile [15/17]\n",
      "Running step: step_make_pynq_driver [16/17]\n",
      "Running step: step_deployment_package [17/17]\n",
      "Completed successfully\n",
      "CPU times: user 16.5 s, sys: 1.72 s, total: 18.3 s\n",
      "Wall time: 38min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5314d097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
